{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.vector_cache', 'TextClassification2.py', '未命名1.ipynb', '.ipynb_checkpoints', 'Task2LstmByIdf.ipynb', 'Task2LstmByWordidx.ipynb', 'Task2TorchText.ipynb', 'train.tsv', 'TextClassification.py', 'test.tsv', 'Task1.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import unicodedata, re, string\n",
    "import nltk\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.listdir(\"/home/xiyu/data/trainee/ZhuYanru\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/home/xiyu/data/trainee/ZhuYanru/train.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"/home/xiyu/data/trainee/ZhuYanru/test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_train.info()\n",
    "#df_train.head()\n",
    "#df_train.loc[df_train['SentenceId'] == 1]\n",
    "dist = df_train.groupby([\"Sentiment\"]).size()\n",
    "#dist = dist / dist.sum()\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.barplot(dist.keys(), dist.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    #print(len(words))\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    #print(len(new_words))\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_numbers(words):\n",
    "    \"\"\"Remove all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(\"\\d+\", \"\", word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "#    words = remove_stopwords(words)\n",
    "    return words\n",
    "def convert_to_onehot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [a, series, of, escapades, demonstrating, the,...\n",
       "1    [a, series, of, escapades, demonstrating, the,...\n",
       "2                                          [a, series]\n",
       "3                                                  [a]\n",
       "4                                             [series]\n",
       "Name: Words, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Words'] = df_train['Phrase'].apply(nltk.word_tokenize)\n",
    "\n",
    "# Second step - passing through prep functions\n",
    "df_train['Words'] = df_train['Words'].apply(normalize) \n",
    "df_train['Words'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 2.1989896611169193e-05, 'series': 0.000943803932728552, 'of': 4.9095706803813153e-05, 'escapades': 0.06833140472954714, 'demonstrating': 0.017981948613038725, 'the': 2.5864166921779687e-05, 'adage': 0.020097471979278574, 'that': 2.9534666636215057e-05, 'what': 0.00018649400854134045, 'is': 5.40981749105749e-05, 'good': 0.00034423881475842394, 'for': 9.692397833978319e-05, 'goose': 0.010048735989639287, 'also': 0.0005216137765614286, 'gander': 0.03796189151641508, 'some': 0.0002064392892131334, 'which': 0.0005080401838628041, 'occasionally': 0.0018568316502594335, 'amuses': 0.03416570236477357, 'but': 6.717597790950369e-05, 'none': 0.0017611186785965762, 'amounts': 0.005694283727462263, 'to': 1.727459923388289e-05, 'much': 0.00018438047687411536, 'story': 0.0001364990106463187}, {'a': 2.748737076396149e-05, 'series': 0.0023595098318213797, 'of': 3.068481675238322e-05, 'escapades': 0.17082851182386785, 'demonstrating': 0.044954871532596814, 'the': 4.310694486963281e-05, 'adage': 0.05024367994819643, 'that': 7.383666659053764e-05, 'what': 0.00046623502135335117, 'is': 6.762271863821862e-05, 'good': 0.0004302985184480299, 'for': 0.00012115497292472898, 'goose': 0.025121839974098215}, {'a': 0.00019241159534773045, 'series': 0.01651656882274966}, {'a': 0.0003848231906954609}, {'series': 0.03303313764549932}, {'of': 3.579895287778042e-05, 'escapades': 0.19929993046117916, 'demonstrating': 0.05244735012136295, 'the': 5.0291435681238276e-05, 'adage': 0.05861762660622917, 'that': 8.614277768896058e-05, 'what': 0.0005439408582455763, 'is': 7.889317174458839e-05, 'good': 0.0005020149381893683, 'for': 0.00014134746841218382, 'goose': 0.029308813303114585}, {'of': 0.0004295874345333651}, {'escapades': 0.21741810595765002, 'demonstrating': 0.05721529104148686, 'the': 5.486338437953267e-05, 'adage': 0.06394650175225002, 'that': 9.397393929704791e-05, 'what': 0.0005933900271769924, 'is': 8.606527826682371e-05, 'good': 0.0005476526598429472, 'for': 0.0001541972382678369, 'goose': 0.03197325087612501}, {'escapades': 2.39159916553415}, {'demonstrating': 0.06293682014563555, 'the': 6.034972281748594e-05, 'adage': 0.07034115192747502, 'that': 0.0001033713332267527, 'what': 0.0006527290298946917, 'is': 9.467180609350607e-05, 'good': 0.000602417925827242, 'for': 0.0001696169620946206, 'goose': 0.03517057596373751}]\n"
     ]
    }
   ],
   "source": [
    "# Third step - creating a list of unique words to be used as dictionary for encoding\n",
    "word_set = set()\n",
    "for l in df_train['Words']:\n",
    "    for e in l:\n",
    "        word_set.add(e)\n",
    "        \n",
    "word_to_int = {word: ii for ii, word in enumerate(word_set, 1)}\n",
    "#句子id-当前句子总词频\n",
    "sentence_word_count_dic=[]\n",
    "#词-文档数\n",
    "Doc_word_dic={}\n",
    "for phrase in df_train['Words']:\n",
    "    sentence_word={}\n",
    "    #词-词频（当前句子）\n",
    "    for word in phrase:\n",
    "        if word not in sentence_word.keys():\n",
    "            sentence_word[word]=1\n",
    "        else:\n",
    "            sentence_word[word]+=1\n",
    "    sentence_word_count_dic.append([len(phrase),sentence_word])\n",
    "    #词-文档数\n",
    "    for setword in sentence_word.keys():\n",
    "        if setword not in Doc_word_dic.keys():\n",
    "            Doc_word_dic[setword]=1\n",
    "        else:\n",
    "            Doc_word_dic[setword]+=1\n",
    "            \n",
    "#print(sentence_word_count_dic[0])\n",
    "doc_idf=[]\n",
    "for line in sentence_word_count_dic:\n",
    "    sentence_idf={}\n",
    "    for word,count in  line[1].items():\n",
    "        idf=(count/line[0])*(math.log(int(len(df_train['Words'])))/Doc_word_dic[word])\n",
    "        sentence_idf[word]=idf\n",
    "    doc_idf.append(sentence_idf)\n",
    "\n",
    "print(doc_idf[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[10214, 2.1989896611169193e-05], [8844, 0.000...\n",
       "1    [[10214, 2.748737076396149e-05], [8844, 0.0023...\n",
       "2    [[10214, 0.00019241159534773045], [8844, 0.016...\n",
       "3                     [[10214, 0.0003848231906954609]]\n",
       "4                        [[8844, 0.03303313764549932]]\n",
       "Name: tfidf, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['tfidf'] = df_train['Words'].apply(lambda l:[])\n",
    "\n",
    "for row_id in range(0,len(df_train['Words'])):\n",
    "    #print(df_train['Words'][row_id])\n",
    "    for word in  df_train['Words'][row_id]:\n",
    "        df_train['tfidf'][row_id].append([word_to_int[word],doc_idf[row_id][word]])\n",
    "df_train['tfidf'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "#df_train['Tokens'] = df_train['Words'].apply(lambda l: [word_to_int[word] for word in l])\n",
    "#df_train['Tokens'].head()\n",
    "max_len = df_train['tfidf'].str.len().max()\n",
    "print(max_len)\n",
    "#df_train['tfidf'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.02140000e+04 2.19898966e-05]\n",
      "  [8.84400000e+03 9.43803933e-04]\n",
      "  [8.13400000e+03 4.90957068e-05]\n",
      "  [1.31170000e+04 6.83314047e-02]\n",
      "  [9.60000000e+02 1.79819486e-02]\n",
      "  [4.98700000e+03 2.58641669e-05]\n",
      "  [1.05960000e+04 2.00974720e-02]\n",
      "  [1.31040000e+04 2.95346666e-05]\n",
      "  [1.14640000e+04 1.86494009e-04]\n",
      "  [6.90400000e+03 5.40981749e-05]\n",
      "  [4.61800000e+03 3.44238815e-04]\n",
      "  [1.14250000e+04 9.69239783e-05]\n",
      "  [4.98700000e+03 2.58641669e-05]\n",
      "  [1.56220000e+04 1.00487360e-02]\n",
      "  [6.90400000e+03 5.40981749e-05]\n",
      "  [1.24770000e+04 5.21613777e-04]\n",
      "  [4.61800000e+03 3.44238815e-04]\n",
      "  [1.14250000e+04 9.69239783e-05]\n",
      "  [4.98700000e+03 2.58641669e-05]\n",
      "  [3.16600000e+03 3.79618915e-02]\n",
      "  [3.59900000e+03 2.06439289e-04]\n",
      "  [8.13400000e+03 4.90957068e-05]\n",
      "  [4.19100000e+03 5.08040184e-04]\n",
      "  [8.08400000e+03 1.85683165e-03]\n",
      "  [1.10280000e+04 3.41657024e-02]\n",
      "  [8.03700000e+03 6.71759779e-05]\n",
      "  [1.28780000e+04 1.76111868e-03]\n",
      "  [8.13400000e+03 4.90957068e-05]\n",
      "  [4.19100000e+03 5.08040184e-04]\n",
      "  [1.47380000e+04 5.69428373e-03]\n",
      "  [1.32470000e+04 1.72745992e-05]\n",
      "  [1.24600000e+03 1.84380477e-04]\n",
      "  [8.13400000e+03 4.90957068e-05]\n",
      "  [1.02140000e+04 2.19898966e-05]\n",
      "  [1.47040000e+04 1.36499011e-04]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.02140000e+04 2.74873708e-05]\n",
      "  [8.84400000e+03 2.35950983e-03]\n",
      "  [8.13400000e+03 3.06848168e-05]\n",
      "  [1.31170000e+04 1.70828512e-01]\n",
      "  [9.60000000e+02 4.49548715e-02]\n",
      "  [4.98700000e+03 4.31069449e-05]\n",
      "  [1.05960000e+04 5.02436799e-02]\n",
      "  [1.31040000e+04 7.38366666e-05]\n",
      "  [1.14640000e+04 4.66235021e-04]\n",
      "  [6.90400000e+03 6.76227186e-05]\n",
      "  [4.61800000e+03 4.30298518e-04]\n",
      "  [1.14250000e+04 1.21154973e-04]\n",
      "  [4.98700000e+03 4.31069449e-05]\n",
      "  [1.56220000e+04 2.51218400e-02]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.02140000e+04 1.92411595e-04]\n",
      "  [8.84400000e+03 1.65165688e-02]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# Pad each phrase representation with zeroes, starting from the beginning of sequence\n",
    "# Will use a combined list of phrases as np array for further work. This is expected format for the Pytorch utils to be used later\n",
    "\n",
    "all_tokens = np.array([t for t in df_train['tfidf']])\n",
    "encoded_labels = np.array([l for l in df_train['Sentiment']])\n",
    "#print(all_tokens[:3])\n",
    "# Create blank rows\n",
    "features = np.zeros((len(all_tokens), max_len,2), dtype=float)\n",
    "# for each phrase, add zeros at the end \n",
    "for i, row in enumerate(all_tokens):\n",
    "    for j in range(0,len(row)):\n",
    "        #print(row[j])\n",
    "        features[i,j][0] = row[j][0]\n",
    "        features[i,j][1] = row[j][1]\n",
    "    #print(features[i, :len(row)])\n",
    "#print first 3 values of the feature matrix \n",
    "print(features[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(124848, 48, 2) \n",
      "Validation set: \t(15606, 48, 2) \n",
      "Test set: \t\t(15606, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of  resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2312\n",
      "289\n",
      "289\n"
     ]
    }
   ],
   "source": [
    "# create Tensor datasets\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 54\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Check the size of the loaders (how many batches inside)\n",
    "print(len(train_loader))\n",
    "print(len(valid_loader))\n",
    "print(len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # linear\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        print(batch_size)\n",
    "        # embeddings and lstm_out\n",
    "        #embeds = self.embedding(x.squeeze(1).long())\n",
    "        \n",
    "        #embeds = x.squeeze(1).long()\n",
    "        embeds = x\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # transform lstm output to input size of linear layers\n",
    "        lstm_out = lstm_out.transpose(0,1)\n",
    "        lstm_out = lstm_out[-1]\n",
    "\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)        \n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (lstm): LSTM(48, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(word_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 5\n",
    "embedding_dim = 48\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.6450e+03, 1.1724e-01],\n",
      "         [1.4189e+04, 7.1691e-03],\n",
      "         [1.0214e+04, 6.4137e-05],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.2670e+03, 2.7575e-04],\n",
      "         [1.1081e+04, 2.8471e-02],\n",
      "         [1.3247e+04, 4.0307e-05],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.4760e+03, 9.3715e-03],\n",
      "         [3.1050e+03, 1.5940e-03],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.8750e+03, 5.1991e-01],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.5778e+04, 1.9526e-03],\n",
      "         [6.5900e+03, 2.7177e-01],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0214e+04, 9.6206e-05],\n",
      "         [5.1000e+02, 9.3715e-03],\n",
      "         [1.2178e+04, 2.3246e-04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "54\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 48, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-25410d4c5898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# get the output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#print(labels.long())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-b2c8f496d036>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#embeds = x.squeeze(1).long()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# transform lstm output to input size of linear layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise RuntimeError(\n\u001b[1;32m    152\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 153\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 48, got 2"
     ]
    }
   ],
   "source": [
    "epochs = 3 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            #print(inputs)\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "        print(inputs)\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "        # calculate the loss and perform backprop\n",
    "        #print(labels.long())\n",
    "        loss = criterion(output, labels.long())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output, labels.long())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.309\n",
      "Test accuracy: 0.488\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output, labels)\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output,1)\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 48)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
