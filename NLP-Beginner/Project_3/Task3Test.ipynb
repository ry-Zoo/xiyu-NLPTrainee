{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchtext\n",
    "from torchtext import data,datasets\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import spacy\n",
    "import re\n",
    "import codecs\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "PREMISE = data.Field(sequential=True, tokenize=tokenizer, lower=True,batch_first=True)\n",
    "PREMISE_LENGTH = data.Field(sequential=False, batch_first=True,use_vocab=False)\n",
    "HYPOTHESIS = data.Field(sequential=True, tokenize=tokenizer, lower=True,batch_first=True)\n",
    "HYPOTHESIS_LENGTH = data.Field(sequential=False, batch_first=True,use_vocab=False)\n",
    "LABEL = data.Field(sequential=False,batch_first=True, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentheses_table = str.maketrans({\"(\": \"\", \")\": \"\"})\n",
    "fw = codecs.open(\"/home/xiyu/data/trainee/ZhuYanru/snli/snli_test_pre.tsv\",'w',encoding='utf8')\n",
    "fw.write(\"idx\\tpremise\\tpremise_length\\thypothesis\\thypothesis_length\\tlable\\r\\n\")\n",
    "with open(\"/home/xiyu/data/trainee/ZhuYanru/snli/snli_test.txt\", \"r\", encoding=\"utf8\") as input_data:\n",
    "    rowid=1\n",
    "    for line in input_data:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        idx=str(rowid)\n",
    "        #idx=line[7].translate(parentheses_table)\n",
    "        lable=line[0]\n",
    "        premise = re.sub(r'[^\\w\\s]','',line[5])\n",
    "        premise_length=str(len([p for p in premise.split(' ')]))\n",
    "        hypothesis = re.sub(r'[^\\w\\s]','',line[6])\n",
    "        hypothesis_length=str(len([h for h in hypothesis.split(' ')]))\n",
    "        #print([idx,lable,premise,hypothesis])\n",
    "        fw.write(idx+'\\t')\n",
    "        fw.write(premise+'\\t')\n",
    "        fw.write(premise_length+'\\t')\n",
    "        fw.write(hypothesis+'\\t')\n",
    "        fw.write(hypothesis_length+'\\t')\n",
    "        if lable=='neutral':\n",
    "            fw.write('0\\n')\n",
    "        elif lable=='entailment':\n",
    "            fw.write('1\\n')\n",
    "        elif lable=='contradiction':\n",
    "            fw.write('2\\n')\n",
    "        rowid+=1\n",
    "        '''\n",
    "        fw.write('{\"idx\":\"'+idx+'\",')\n",
    "        fw.write('\"premise\":\"'+premise+'\",')\n",
    "        fw.write('\"hypothesis\":\"'+hypothesis+'\",')\n",
    "        fw.write('\"lable\":\"'+lable+'\"}')\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idx', 'premise', 'premise_length', 'hypothesis', 'hypothesis_length', 'lable']\n",
      "['1', 'Two women are embracing while holding to go packages', '9', 'The sisters are hugging goodbye while holding to go packages after just eating lunch', '14', '0']\n",
      "['2', 'Two women are embracing while holding to go packages', '9', 'Two woman are holding packages', '5', '1']\n",
      "['3', 'Two women are embracing while holding to go packages', '9', 'The men are fighting outside a deli', '7', '2']\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/xiyu/data/trainee/ZhuYanru/snli/snli_test_pre.tsv\", \"r\", encoding=\"utf8\") as test_data:\n",
    "    for line in test_data:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu=torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_data = data.TabularDataset(\n",
    "        path='./snli_test_pre.tsv',format='tsv',\n",
    "        skip_header=True,\n",
    "        #fields = {\"idx\":(\"idx\",None),\"premise\":(\"premise\", PREMISE),\"hypothesis\":(\"hypothesis\", HYPOTHESIS),\"lable\":(\"lable\",LABEL)})\n",
    "        fields =[('idx', None),('premise', PREMISE),('premise_length',PREMISE_LENGTH),('hypothesis', HYPOTHESIS),('hypothesis_length',HYPOTHESIS_LENGTH),('lable',LABEL)])\n",
    "\n",
    "\n",
    "PREMISE.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
    "HYPOTHESIS.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
    "PREMISE_LENGTH.build_vocab()\n",
    "HYPOTHESIS_LENGTH.build_vocab()\n",
    "LABEL.build_vocab()\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=16\n",
    "train_iterator,valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data,valid_data), \n",
    "    sort_key=lambda x: len(x.premise),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "print(len(train_iterator))\n",
    "print(len(valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 18,  2, 13, 12, 21,  3, 19, 11,  4,  7, 14,  9, 15],\n",
      "        [ 5, 16,  2, 10, 17,  6,  8,  1,  1,  1,  1,  1,  1,  1]],\n",
      "       device='cuda:0')\n",
      "tensor([14,  7], device='cuda:0')\n",
      "tensor([[20, 22,  2,  3,  4]], device='cuda:0')\n",
      "tensor([5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for id, batch in enumerate(train_iterator):\n",
    "    premise,premise_length,hypothesis,hypothesis_length,lable =batch.premise,batch.premise_length,batch.hypothesis,batch.hypothesis_length, batch.lable\n",
    "    #print(batch.premise.shape,batch.premise_length.shape,batch.hypothesis.shape,batch.hypothesis_length.shape,batch.lable.shape)\n",
    "    print(hypothesis)\n",
    "    print(hypothesis_length)\n",
    "for id, batch in enumerate(valid_iterator):\n",
    "    premise,premise_length,hypothesis,hypothesis_length,lable =batch.premise,batch.premise_length,batch.hypothesis,batch.hypothesis_length, batch.lable\n",
    "    #print(batch.premise.shape,batch.premise_length.shape,batch.hypothesis.shape,batch.hypothesis_length.shape,batch.lable.shape)\n",
    "    print(hypothesis)\n",
    "    print(hypothesis_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeLayerRNN(nn.Module):\n",
    "\n",
    "    def __init__(self,  embedding_dim, hidden_dim , n_layers=1,bias=True,drop_prob=0.2,bidirectional=False):\n",
    "        super(EncodeLayerRNN, self).__init__()\n",
    "                 \n",
    "        #self.vocab_size=vocab_size\n",
    "        #self.input_size=input_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bias = bias\n",
    "        self.drop_prob = drop_prob\n",
    "        self.bidirectional = bidirectional\n",
    "        #随机生成Embedding\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim) \n",
    "        # 若使用预训练的词向量，需在此处指定预训练的权重\n",
    "        #使用预训练的文件Embedding \n",
    "        #self.word_embeddings = nn.Embedding.from_pretrained(PREMISE.vocab.vectors)\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(HYPOTHESIS.vocab.vectors)\n",
    "        #self.word_embeddings.weight.data.copy_(TEXT.vocab.vectors)\n",
    "        self.word_embeddings.weight.data.requires_grad=False\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,dropout=drop_prob,bidirectional=False)  \n",
    "        \n",
    "        #self.dropout = nn.Dropout(drop_prob)\n",
    "        #self.decoder = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, sequences_batch,sequences_lengths):\n",
    "        #print(sequences_batch.size())\n",
    "        #print(sequences_lengths)\n",
    "        embeds = self.word_embeddings(sequences_batch)\n",
    "        #对batch中的句子长度从大到小排序sorted_batch，并记录原来的句子顺序restoration_index\n",
    "        #print(embeds)\n",
    "        #print(sequences_lengths)\n",
    "        sorted_seq_lens, sorting_index =sequences_lengths.sort(0, descending=True)\n",
    "        #print(sorted_seq_lens)\n",
    "        #print(1/0)\n",
    "        #print(sorting_index)\n",
    "        sorted_batch = embeds.index_select(0, sorting_index)\n",
    "        #print(sorted_batch.size())\n",
    "        idx_range =sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n",
    "        #idx_range =torch.arange(0, len(sequences_lengths)).cuda()\n",
    "        #print(idx_range)\n",
    "        _, reverse_mapping = sorting_index.sort(0, descending=False)\n",
    "        #print(reverse_mapping)\n",
    "        restoration_index = idx_range.index_select(0, reverse_mapping)\n",
    "        #对句子进行压缩操作，避免最后输出为许多padding结果\n",
    "        packed_batch = nn.utils.rnn.pack_padded_sequence(sorted_batch,sorted_seq_lens,batch_first=True)\n",
    "        #输入lstm\n",
    "        outputs, _ = self.lstm(packed_batch, None)\n",
    "        #print(outputs.size())\n",
    "        #print(outputs)\n",
    "        #恢复到padding状态\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs,batch_first=True)\n",
    "        #print(outputs.size())\n",
    "        #print(outputs)\n",
    "        #恢复到原batch次序\n",
    "        reordered_outputs = outputs.index_select(0, restoration_index)\n",
    "  \n",
    "        return reordered_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mask(sequences_batch, sequences_lengths):\n",
    "\n",
    "    batch_size = sequences_batch.size()[0]\n",
    "    max_length = torch.max(sequences_lengths)\n",
    "    mask = torch.ones(batch_size, max_length, dtype=torch.float)\n",
    "    mask[sequences_batch[:, :max_length] == 0] = 0.0\n",
    "    return mask\n",
    "\n",
    "def weighted_sum(tensor, weights, mask):\n",
    "\n",
    "    weighted_sum = weights.bmm(tensor)\n",
    "\n",
    "    while mask.dim() < weighted_sum.dim():\n",
    "        mask = mask.unsqueeze(1)\n",
    "    mask = mask.transpose(-1, -2)\n",
    "    mask = mask.expand_as(weighted_sum).contiguous().float()\n",
    "\n",
    "    return weighted_sum * mask\n",
    "\n",
    "def masked_softmax(tensor, mask):\n",
    "    tensor_shape = tensor.size()\n",
    "    reshaped_tensor = tensor.view(-1, tensor_shape[-1])\n",
    "    #print(mask.size())\n",
    "    #print(mask)\n",
    "    #print(tensor.size())\n",
    "    # Reshape the mask so it matches the size of the input tensor.\n",
    "    while mask.dim() < tensor.dim():\n",
    "        mask = mask.unsqueeze(1)\n",
    "    print(mask.size())\n",
    "    mask = mask.expand_as(tensor).contiguous().float()\n",
    "    reshaped_mask = mask.view(-1, mask.size()[-1])\n",
    "    print(reshaped_mask.size())\n",
    "    print(reshaped_tensor.size())\n",
    "    #对每一行进行softmax\n",
    "    #print(reshaped_tensor * reshaped_mask)\n",
    "    result = nn.functional.softmax(reshaped_tensor * reshaped_mask.cuda(), dim=-1)\n",
    "    #print('A:',result.size())\n",
    "    #疑问：为何需要在经过softmax层之后再乘mask\n",
    "    result = result * reshaped_mask.cuda()\n",
    "    #print('B:',result.size())\n",
    "    # 1e-13 is added to avoid divisions by zero.\n",
    "    result = result / (result.sum(dim=-1, keepdim=True) + 1e-13)\n",
    "\n",
    "    return result.view(*tensor_shape)\n",
    "\n",
    "class SoftmaxAttention(nn.Module):\n",
    "\n",
    "    def forward(self,\n",
    "                premise_batch,\n",
    "                premise_mask,\n",
    "                hypothesis_batch,\n",
    "                hypothesis_mask):\n",
    "\n",
    "        # Dot product between premises and hypotheses in each sequence of\n",
    "        # the batch.\n",
    "        similarity_matrix = premise_batch.bmm(hypothesis_batch.transpose(2, 1)\n",
    "                                                              .contiguous())\n",
    "        #print(similarity_matrix.size())\n",
    "        #print(similarity_matrix)\n",
    "        # Softmax attention weights.\n",
    "        prem_hyp_attn = masked_softmax(similarity_matrix, hypothesis_mask)\n",
    "        hyp_prem_attn = masked_softmax(similarity_matrix.transpose(1, 2)\n",
    "                                                        .contiguous(),\n",
    "                                       premise_mask)\n",
    "\n",
    "        # Weighted sums of the hypotheses for the the premises attention,\n",
    "        # and vice-versa for the attention of the hypotheses.\n",
    "        attended_premises = weighted_sum(hypothesis_batch,\n",
    "                                         prem_hyp_attn,\n",
    "                                         premise_mask.cuda())\n",
    "        attended_hypotheses = weighted_sum(premise_batch,\n",
    "                                           hyp_prem_attn,\n",
    "                                           hypothesis_mask.cuda())\n",
    "\n",
    "        return attended_premises, attended_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncodeLayerRNN(\n",
      "  (word_embeddings): Embedding(23, 300)\n",
      "  (lstm): LSTM(300, 300, dropout=0.2)\n",
      ")\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "torch.Size([2, 9, 14])\n",
      "tensor([[[ 2.4960e-02, -6.0764e-02, -1.5055e-01, -1.0399e-01, -3.0015e-02,\n",
      "          -7.1610e-02, -1.2968e-01, -7.4623e-02, -2.0779e-02,  4.8772e-02,\n",
      "           1.7189e-02,  1.0484e-03,  1.7993e-01,  4.1333e-01],\n",
      "         [ 2.9397e-01,  2.7375e-01,  3.5641e-01,  2.2192e-01,  1.5435e-01,\n",
      "           3.3914e-01,  3.6200e-01,  4.1390e-01,  4.6000e-01,  3.2771e-01,\n",
      "           4.6404e-01,  4.8587e-01,  5.6592e-01,  4.8381e-01],\n",
      "         [ 4.4390e-01,  5.5792e-01,  1.2346e+00,  7.2402e-01,  4.8772e-01,\n",
      "           7.3505e-01,  7.3953e-01,  8.6767e-01,  9.1199e-01,  7.4952e-01,\n",
      "           7.3738e-01,  8.5360e-01,  8.1665e-01,  5.4702e-01],\n",
      "         [ 3.9686e-01,  4.9976e-01,  9.9596e-01,  7.6813e-01,  5.5669e-01,\n",
      "           7.6897e-01,  1.2074e+00,  1.0319e+00,  8.9929e-01,  7.5663e-01,\n",
      "           7.5683e-01,  8.0096e-01,  7.9022e-01,  5.3393e-01],\n",
      "         [ 3.6002e-01,  3.4136e-01,  7.8242e-01,  6.8963e-01,  5.2611e-01,\n",
      "           7.6105e-01,  9.7682e-01,  8.4055e-01,  8.1955e-01,  8.1571e-01,\n",
      "           8.4567e-01,  8.7672e-01,  1.6309e+00,  1.2674e+00],\n",
      "         [ 7.0644e-01,  5.8704e-01,  8.9275e-01,  6.4802e-01,  4.9804e-01,\n",
      "           7.6741e-01,  8.7300e-01,  9.6747e-01,  9.7436e-01,  8.0351e-01,\n",
      "           9.3355e-01,  1.0144e+00,  1.2639e+00,  1.0418e+00],\n",
      "         [ 6.3162e-01,  5.5217e-01,  7.9903e-01,  5.8069e-01,  4.4743e-01,\n",
      "           7.9278e-01,  8.2924e-01,  9.8309e-01,  9.8813e-01,  7.5446e-01,\n",
      "           1.1852e+00,  1.1666e+00,  1.2119e+00,  9.9489e-01],\n",
      "         [ 4.3324e-01,  3.7441e-01,  6.6571e-01,  4.8238e-01,  4.1105e-01,\n",
      "           5.9955e-01,  6.5119e-01,  7.8609e-01,  7.8098e-01,  1.4080e+00,\n",
      "           1.2188e+00,  1.0206e+00,  1.0904e+00,  9.4072e-01],\n",
      "         [ 5.1066e-01,  4.4329e-01,  6.9191e-01,  3.8901e-01,  3.9803e-01,\n",
      "           5.9912e-01,  6.7960e-01,  8.9316e-01,  8.3052e-01,  1.0634e+00,\n",
      "           1.0868e+00,  1.0461e+00,  9.7632e-01,  8.9821e-01]],\n",
      "\n",
      "        [[ 2.4960e-02, -5.9073e-02, -1.5031e-01, -1.9917e-01, -9.7494e-02,\n",
      "          -1.2653e-03,  9.3681e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 2.9397e-01,  4.7107e-01,  4.4160e-01,  1.0618e+00,  7.9780e-01,\n",
      "           5.0114e-01,  6.0748e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 4.4390e-01,  8.1113e-01,  1.3529e+00,  1.3485e+00,  1.1547e+00,\n",
      "           8.6637e-01,  5.1442e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 3.9686e-01,  6.5806e-01,  1.0863e+00,  1.1607e+00,  1.0623e+00,\n",
      "           8.9928e-01,  4.4741e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 3.6002e-01,  6.2422e-01,  9.3186e-01,  1.0373e+00,  9.8325e-01,\n",
      "           8.3963e-01,  6.3438e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 7.0644e-01,  8.4378e-01,  1.0266e+00,  1.0711e+00,  1.0073e+00,\n",
      "           9.8287e-01,  6.2816e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 6.3162e-01,  8.0604e-01,  9.3661e-01,  1.0474e+00,  9.9485e-01,\n",
      "           1.0101e+00,  5.7894e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 4.3324e-01,  5.6453e-01,  7.6783e-01,  7.4094e-01,  7.2692e-01,\n",
      "           7.8024e-01,  5.1776e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 5.1066e-01,  6.2141e-01,  7.8643e-01,  6.8609e-01,  6.9071e-01,\n",
      "           1.2387e+00,  7.5860e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       device='cuda:0', grad_fn=<BmmBackward>)\n",
      "torch.Size([2, 1, 14])\n",
      "torch.Size([18, 14])\n",
      "torch.Size([18, 14])\n",
      "A: torch.Size([18, 14])\n",
      "B: torch.Size([18, 14])\n",
      "torch.Size([2, 1, 9])\n",
      "torch.Size([28, 9])\n",
      "torch.Size([28, 9])\n",
      "A: torch.Size([28, 9])\n",
      "B: torch.Size([28, 9])\n",
      "torch.Size([2, 9, 1200])\n",
      "torch.Size([2, 14, 1200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#编码层\n",
    "Encoded = EncodeLayerRNN(embedding_dim=300, hidden_dim=300, n_layers=1)\n",
    "print(Encoded)\n",
    "\n",
    "#Attention层\n",
    "Attention = SoftmaxAttention()\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    Encoded.cuda()\n",
    "    \n",
    "Encoded.train()\n",
    "losses=[]\n",
    "# train for some number of epochs\n",
    "for epoch, batch in enumerate(train_iterator):\n",
    "    #optimizer.zero_grad()\n",
    "    #start = time.time()\n",
    "    #print('premise_length')\n",
    "    #print(batch.premise_length)\n",
    "    mask_premise=get_mask(batch.premise,batch.premise_length)\n",
    "    mask_hypothesis=get_mask(batch.hypothesis,batch.hypothesis_length)\n",
    "    print(mask_premise)\n",
    "    print(mask_hypothesis)\n",
    "    premise_encoded = Encoded(batch.premise,batch.premise_length)\n",
    "    #print('hypothesis_length')\n",
    "    #print(batch.hypothesis_length)\n",
    "    hypothesis_encoded = Encoded(batch.hypothesis,batch.hypothesis_length)\n",
    "    #print(premise_encoded.size())\n",
    "    #print(hypothesis_encoded.size())\n",
    "    attended_premises,attended_hypotheses=Attention(premise_encoded,mask_premise,hypothesis_encoded,mask_hypothesis)\n",
    "    #print(attended_premises)\n",
    "    #print(attended_hypotheses)\n",
    "    enhanced_premises = torch.cat([premise_encoded,\n",
    "                               attended_premises,\n",
    "                               premise_encoded - attended_premises,\n",
    "                               premise_encoded * attended_premises],\n",
    "                              dim=-1)\n",
    "    enhanced_hypotheses = torch.cat([hypothesis_encoded,\n",
    "                                 attended_hypotheses,\n",
    "                                 hypothesis_encoded - attended_hypotheses,\n",
    "                                 hypothesis_encoded * attended_hypotheses],\n",
    "                                dim=-1)\n",
    "    print(enhanced_premises.size())\n",
    "    print(enhanced_hypotheses.size())\n",
    "    #loss = loss_funtion(predicted, batch.Sentiment)\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    #losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
