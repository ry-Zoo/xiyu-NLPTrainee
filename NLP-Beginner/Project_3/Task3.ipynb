{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import argparse\n",
    "import zipfile\n",
    "import wget\n",
    "import time\n",
    "import pickle\n",
    "import fnmatch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset,DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, targetdir):\n",
    "    \"\"\"下载\"\"\"\n",
    "    print(\"* Downloading data from {}...\".format(url))\n",
    "    filepath = os.path.join(targetdir, url.split('/')[-1])\n",
    "    wget.download(url, filepath)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def unzip(filepath):\n",
    "    \"\"\"解压\"\"\"\n",
    "    print(\"\\n* Extracting: {}...\".format(filepath))\n",
    "    dirpath = os.path.dirname(filepath)\n",
    "    with zipfile.ZipFile(filepath) as zf:\n",
    "        for name in zf.namelist():\n",
    "            if \"__MACOSX\" in name or\\\n",
    "               \".DS_Store\" in name or\\\n",
    "               \"Icon\" in name:\n",
    "                continue\n",
    "            zf.extract(name, dirpath)\n",
    "    os.remove(filepath)\n",
    "\n",
    "\n",
    "def download_unzip(url, targetdir):\n",
    "    filepath = os.path.join(targetdir, url.split('/')[-1])\n",
    "    target = os.path.join(targetdir,\n",
    "                          \".\".join((url.split('/')[-1]).split('.')[:-1]))\n",
    "\n",
    "    if not os.path.exists(targetdir):\n",
    "        print(\"* Creating target directory {}...\".format(targetdir))\n",
    "        os.makedirs(targetdir)\n",
    "\n",
    "    # 发现解压文件，跳过下载和解压\n",
    "    if os.path.exists(target) or os.path.exists(target + \".txt\"):\n",
    "        print(\"* Found unzipped data in {}, skipping download and unzip...\"\n",
    "              .format(targetdir))\n",
    "    # 发现压缩文件，跳过下载\n",
    "    elif os.path.exists(filepath):\n",
    "        print(\"* Found zipped data in {} - skipping download...\"\n",
    "              .format(targetdir))\n",
    "        unzip(filepath)\n",
    "    # 下载 & 解压\n",
    "    else:\n",
    "        unzip(download(url, targetdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Fetching the dataset: ==============================\n",
      "* Found unzipped data in data_task3/dataset, skipping download and unzip...\n",
      "============================== Fetching the word embeddings: ==============================\n",
      "* Found unzipped data in data_task3/embeddings, skipping download and unzip...\n"
     ]
    }
   ],
   "source": [
    "# 相应的URL\n",
    "dataset_url = \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
    "embeddings_url = \"http://www-nlp.stanford.edu/data/glove.840B.300d.zip\"\n",
    "\n",
    "target_dir = \"data_task3\"\n",
    "\n",
    "print(30*\"=\", \"Fetching the dataset:\", 30*'=')\n",
    "download_unzip(dataset_url, os.path.join(target_dir, \"dataset\"))\n",
    "\n",
    "print(30*\"=\", \"Fetching the word embeddings:\", 30*\"=\")\n",
    "download_unzip(embeddings_url, os.path.join(target_dir, \"embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    ''' 预处理类 '''\n",
    "    def __init__(self, lowercase=False, ignore_punctuation=False, num_words=None, \n",
    "                 stopwords=[], labeldict={}, bos=None, eos=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lowercase:是否转换为小写，默认否\n",
    "            ignore_punctuation: 是否忽略标点符号，默认否\n",
    "            num_words: worddict中使用的词数量，默认None表示全部\n",
    "            stopwords: 构建worddict时的停用词表，默认为空\n",
    "            bos: 句子起始 默认None\n",
    "            eos: 句子结尾 默认None\n",
    "        \"\"\"\n",
    "        self.lowercase = lowercase\n",
    "        self.ignore_punctuation = ignore_punctuation\n",
    "        self.num_words = num_words\n",
    "        self.stopwords = stopwords\n",
    "        self.labeldict = labeldict\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "    def read_data(self, filepath):\n",
    "        \"\"\"\n",
    "        从NLI数据集读取ids，premises，hypotheses，labels，返回相应字典\n",
    "        \"\"\"\n",
    "        with open(filepath, \"r\", encoding=\"utf8\") as input_data:\n",
    "            ids, premises, hypotheses, labels = [], [], [], []\n",
    "\n",
    "            # 括号和标点符号的替换方式\n",
    "            parentheses_table = str.maketrans({\"(\": None, \")\": None})\n",
    "            punct_table = str.maketrans({key: \" \" for key in string.punctuation})\n",
    "\n",
    "            # 忽略文件首行\n",
    "            next(input_data)\n",
    "\n",
    "            # 处理每行\n",
    "            for line in input_data:\n",
    "                line = line.strip().split(\"\\t\")\n",
    "\n",
    "                # 忽略无标签句子\n",
    "                if line[0] == \"-\":\n",
    "                    continue\n",
    "\n",
    "                pair_id = line[7] # captionID?\n",
    "                premise = line[1]\n",
    "                hypothesis = line[2]\n",
    "\n",
    "                # 移除括号\n",
    "                premise = premise.translate(parentheses_table)\n",
    "                hypothesis = hypothesis.translate(parentheses_table)\n",
    "\n",
    "                if self.lowercase:\n",
    "                    premise = premise.lower()\n",
    "                    hypothesis = hypothesis.lower()\n",
    "\n",
    "                if self.ignore_punctuation:\n",
    "                    premise = premise.translate(punct_table)\n",
    "                    hypothesis = hypothesis.translate(punct_table)\n",
    "\n",
    "                # 将句子分成词列表\n",
    "                premises.append([w for w in premise.rstrip().split()\n",
    "                                 if w not in self.stopwords])\n",
    "                hypotheses.append([w for w in hypothesis.rstrip().split()\n",
    "                                   if w not in self.stopwords])\n",
    "                labels.append(line[0])\n",
    "                ids.append(pair_id)\n",
    "\n",
    "            return {\"ids\": ids,\n",
    "                    \"premises\": premises,\n",
    "                    \"hypotheses\": hypotheses,\n",
    "                    \"labels\": labels}\n",
    "\n",
    "    def build_worddict(self, data):\n",
    "        \"\"\"\n",
    "        构建词典（词-索引）\n",
    "        Args:\n",
    "            data: read_data所返回dict\n",
    "        \"\"\"\n",
    "        words = []\n",
    "        [words.extend(sentence) for sentence in data[\"premises\"]]\n",
    "        [words.extend(sentence) for sentence in data[\"hypotheses\"]]\n",
    "\n",
    "        counts = Counter(words)\n",
    "        num_words = self.num_words\n",
    "        if self.num_words is None:\n",
    "            num_words = len(counts)\n",
    "\n",
    "        self.worddict = {}\n",
    "\n",
    "        # 索引0 -- padding\n",
    "        # 索引1 -- out-of-vocabulary words\n",
    "        # 索引2 -- beginning of sentence\n",
    "        # 索引3 -- end of sentence\n",
    "        self.worddict[\"_PAD_\"] = 0\n",
    "        self.worddict[\"_OOV_\"] = 1\n",
    "\n",
    "        offset = 2\n",
    "        if self.bos:\n",
    "            self.worddict[\"_BOS_\"] = 2\n",
    "            offset += 1\n",
    "        if self.eos:\n",
    "            self.worddict[\"_EOS_\"] = 3\n",
    "            offset += 1\n",
    "\n",
    "        for i, word in enumerate(counts.most_common(num_words)):\n",
    "            self.worddict[word[0]] = i + offset\n",
    "\n",
    "        if self.labeldict == {}:\n",
    "            label_names = set(data[\"labels\"])\n",
    "            self.labeldict = {label_name: i\n",
    "                              for i, label_name in enumerate(label_names)}\n",
    "\n",
    "    def words_to_indices(self, sentence):\n",
    "        \"\"\"\n",
    "        将句子中词转换为词典中对应的索引\n",
    "        Args:\n",
    "            sentence: 词列表\n",
    "        Returns:\n",
    "            索引列表\n",
    "        \"\"\"\n",
    "        indices = []\n",
    "\n",
    "        # BOS\n",
    "        if self.bos:\n",
    "            indices.append(self.worddict[\"_BOS_\"])\n",
    "\n",
    "        for word in sentence:\n",
    "            if word in self.worddict:\n",
    "                index = self.worddict[word]\n",
    "            else:\n",
    "\n",
    "                # out-of-vocabulary word (OOV).\n",
    "                index = self.worddict[\"_OOV_\"]\n",
    "            indices.append(index)\n",
    "\n",
    "        # EOS\n",
    "        if self.eos:\n",
    "            indices.append(self.worddict[\"_EOS_\"])\n",
    "\n",
    "        return indices\n",
    "\n",
    "    def indices_to_words(self, indices):\n",
    "        \"\"\"\n",
    "        将索引转换为词\n",
    "        \"\"\"\n",
    "        return [list(self.worddict.keys())[list(self.worddict.values())\n",
    "                                           .index(i)]\n",
    "                for i in indices]\n",
    "\n",
    "    def transform_to_indices(self, data):\n",
    "        \"\"\"\n",
    "        将premises和hypotheses，labels转换为索引\n",
    "        Args:\n",
    "            data: read_data返回的dict\n",
    "        Returns:\n",
    "            包含转换后premises, hypotheses,labels的dict.\n",
    "        \"\"\"\n",
    "        transformed_data = {\"ids\": [],\n",
    "                            \"premises\": [],\n",
    "                            \"hypotheses\": [],\n",
    "                            \"labels\": []}\n",
    "\n",
    "        for i, premise in enumerate(data[\"premises\"]):\n",
    "            # Ignore sentences that have a label for which no index was\n",
    "            # defined in 'labeldict'.\n",
    "            label = data[\"labels\"][i]\n",
    "            if label not in self.labeldict and label != \"hidden\":\n",
    "                continue\n",
    "\n",
    "            transformed_data[\"ids\"].append(data[\"ids\"][i])\n",
    "\n",
    "            if label == \"hidden\":\n",
    "                transformed_data[\"labels\"].append(-1)\n",
    "            else:\n",
    "                transformed_data[\"labels\"].append(self.labeldict[label])\n",
    "\n",
    "            indices = self.words_to_indices(premise)\n",
    "            transformed_data[\"premises\"].append(indices)\n",
    "\n",
    "            indices = self.words_to_indices(data[\"hypotheses\"][i])\n",
    "            transformed_data[\"hypotheses\"].append(indices)\n",
    "\n",
    "        return transformed_data\n",
    "\n",
    "    def build_embedding_matrix(self, embeddings_file):\n",
    "        \"\"\"\n",
    "        为当前词典创建预训练词向量矩阵\n",
    "        Args:\n",
    "            embeddings_file: 预训练词向量\n",
    "        Returns:\n",
    "            numpy矩阵 -- 大小(num_words + n_special_tokens, embedding_dim)\n",
    "            n_special_tokens: padding/oov/bos/eos\n",
    "        \"\"\"\n",
    "        # 加载词向量\n",
    "        embeddings = {}\n",
    "        with open(embeddings_file, \"r\", encoding=\"utf8\") as input_data:\n",
    "            for line in input_data:\n",
    "                line = line.split()\n",
    "\n",
    "                try:\n",
    "                    # 检查是否为词向量数据\n",
    "                    float(line[1])\n",
    "                    word = line[0]\n",
    "                    if word in self.worddict:\n",
    "                        embeddings[word] = line[1:]\n",
    "\n",
    "                # 忽略无用行\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "        num_words = len(self.worddict)\n",
    "        embedding_dim = len(list(embeddings.values())[0])\n",
    "        embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "        # 构建矩阵\n",
    "        missed = 0\n",
    "        for word, i in self.worddict.items():\n",
    "            if word in embeddings:\n",
    "                embedding_matrix[i] = np.array(embeddings[word], dtype=float)\n",
    "            else:\n",
    "                if word == \"_PAD_\":\n",
    "                    continue\n",
    "                missed += 1\n",
    "                # oov词高斯随机初始化\n",
    "                embedding_matrix[i] = np.random.normal(size=(embedding_dim))\n",
    "        print(\"Missed words: \", missed)\n",
    "\n",
    "        return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "预处理数据集和词向量\n",
    "\"\"\"\n",
    "def preprocess_SNLI_data(inputdir, embeddings_file, targetdir, lowercase=False, ignore_punctuation=False,\n",
    "                         num_words=None, stopwords=[], labeldict={}, bos=None, eos=None):\n",
    "\n",
    "    if not os.path.exists(targetdir):\n",
    "        os.makedirs(targetdir)\n",
    "\n",
    "    # 获取训练，验证，测试文件\n",
    "    train_file = \"\"\n",
    "    dev_file = \"\"\n",
    "    test_file = \"\"\n",
    "    for file in os.listdir(inputdir):\n",
    "        if fnmatch.fnmatch(file, \"*_train.txt\"):\n",
    "            train_file = file\n",
    "        elif fnmatch.fnmatch(file, \"*_dev.txt\"):\n",
    "            dev_file = file\n",
    "        elif fnmatch.fnmatch(file, \"*_test.txt\"):\n",
    "            test_file = file\n",
    "\n",
    "    # ------------------------- 训练数据集预处理 -------------------------- #\n",
    "    preprocessor = Preprocessor(lowercase=lowercase, ignore_punctuation=ignore_punctuation,\n",
    "                                num_words=num_words, stopwords=stopwords,\n",
    "                                labeldict=labeldict, bos=bos, eos=eos)\n",
    "\n",
    "    print(30*\"=\", \" Preprocessing train set \", 30*\"=\")\n",
    "    print(\"\\t* Reading data...\")\n",
    "    data = preprocessor.read_data(os.path.join(inputdir, train_file))\n",
    "\n",
    "    print(\"\\t* Computing worddict and saving it...\")\n",
    "    preprocessor.build_worddict(data)\n",
    "    with open(os.path.join(targetdir, \"worddict.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(preprocessor.worddict, pkl_file)\n",
    "\n",
    "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
    "    transformed_data = preprocessor.transform_to_indices(data)\n",
    "    print(\"\\t* Saving result...\")\n",
    "    with open(os.path.join(targetdir, \"train_data.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(transformed_data, pkl_file)\n",
    "\n",
    "    # ------------------------ 验证数据集预处理 --------------------------- #\n",
    "    print(30*\"=\", \" Preprocessing dev set \", 30*\"=\")\n",
    "    print(\"\\t* Reading data...\")\n",
    "    data = preprocessor.read_data(os.path.join(inputdir, dev_file))\n",
    "\n",
    "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
    "    transformed_data = preprocessor.transform_to_indices(data)\n",
    "    print(\"\\t* Saving result...\")\n",
    "    with open(os.path.join(targetdir, \"dev_data.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(transformed_data, pkl_file)\n",
    "\n",
    "    # ------------------------ 测试数据集预处理 --------------------------- #\n",
    "    print(30*\"=\", \" Preprocessing test set \", 30*\"=\")\n",
    "    print(\"\\t* Reading data...\")\n",
    "    data = preprocessor.read_data(os.path.join(inputdir, test_file))\n",
    "\n",
    "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
    "    transformed_data = preprocessor.transform_to_indices(data)\n",
    "    print(\"\\t* Saving result...\")\n",
    "    with open(os.path.join(targetdir, \"test_data.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(transformed_data, pkl_file)\n",
    "\n",
    "    # ------------------------ 词向量预处理 ----------------------------- #\n",
    "    print(30*\"=\", \" Preprocessing embeddings \", 30*\"=\")\n",
    "    print(\"\\t* Building embedding matrix and saving it...\")\n",
    "    embed_matrix = preprocessor.build_embedding_matrix(embeddings_file)\n",
    "    with open(os.path.join(targetdir, \"embeddings.pkl\"), \"wb\") as pkl_file:\n",
    "        pickle.dump(embed_matrix, pkl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================  Preprocessing train set  ==============================\n",
      "\t* Reading data...\n",
      "\t* Computing worddict and saving it...\n",
      "\t* Transforming words in premises and hypotheses to indices...\n",
      "\t* Saving result...\n",
      "==============================  Preprocessing dev set  ==============================\n",
      "\t* Reading data...\n",
      "\t* Transforming words in premises and hypotheses to indices...\n",
      "\t* Saving result...\n",
      "==============================  Preprocessing test set  ==============================\n",
      "\t* Reading data...\n",
      "\t* Transforming words in premises and hypotheses to indices...\n",
      "\t* Saving result...\n",
      "==============================  Preprocessing embeddings  ==============================\n",
      "\t* Building embedding matrix and saving it...\n",
      "Missed words:  4045\n"
     ]
    }
   ],
   "source": [
    "default_config = \"config/snli_preprocessing.json\" # 配置文件\n",
    "\n",
    "with open(default_config, \"r\") as cfg_file:\n",
    "    config = json.load(cfg_file)\n",
    "\n",
    "### 数据预处理 \n",
    "preprocess_SNLI_data(\n",
    "    os.path.normpath(config[\"data_dir\"]), # \"data_task3/dataset/snli_1.0\"\n",
    "    os.path.normpath(config[\"embeddings_file\"]), # \"data_task3/embeddings/glove.840B.300d.txt\",\n",
    "    os.path.normpath(config[\"target_dir\"]), # \"data_task3/preprocessed/SNLI\"\n",
    "    lowercase=config[\"lowercase\"], # false\n",
    "    ignore_punctuation=config[\"ignore_punctuation\"], # false\n",
    "    num_words=config[\"num_words\"], # None\n",
    "    stopwords=config[\"stopwords\"], # []\n",
    "    labeldict=config[\"labeldict\"], # {'e':0, 'n':1, 'c':2}\n",
    "    bos=config[\"bos\"], # '_BOS_'\n",
    "    eos=config[\"eos\"] # '_EOS_'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, padding_idx=0, max_premise_length=None,\n",
    "                 max_hypothesis_length=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: 包含预处理premises, hypotheses 和 labels的字典.\n",
    "            padding_idx: 用于padding的索引, 默认0.\n",
    "            max_premise_length: premises的最大长度. 默认None，使用data中premises最大长度.\n",
    "            max_hypothesis_length: hypotheses的最大长度. 默认None，使用data中hypotheses最大长度.\n",
    "        \"\"\"\n",
    "        self.premises_lengths = [len(seq) for seq in data[\"premises\"]]\n",
    "        self.max_premise_length = max_premise_length\n",
    "        if self.max_premise_length is None:\n",
    "            self.max_premise_length = max(self.premises_lengths)\n",
    "\n",
    "        self.hypotheses_lengths = [len(seq) for seq in data[\"hypotheses\"]]\n",
    "        self.max_hypothesis_length = max_hypothesis_length\n",
    "        if self.max_hypothesis_length is None:\n",
    "            self.max_hypothesis_length = max(self.hypotheses_lengths)\n",
    "\n",
    "        self.num_sequences = len(data[\"premises\"])\n",
    "\n",
    "        self.data = {\"ids\": [],\n",
    "                     \"premises\": torch.ones((self.num_sequences,\n",
    "                                             self.max_premise_length),\n",
    "                                            dtype=torch.long) * padding_idx,\n",
    "                     \"hypotheses\": torch.ones((self.num_sequences,\n",
    "                                               self.max_hypothesis_length),\n",
    "                                              dtype=torch.long) * padding_idx,\n",
    "                     \"labels\": torch.tensor(data[\"labels\"], dtype=torch.long)}\n",
    "\n",
    "        for i, premise in enumerate(data[\"premises\"]):\n",
    "            self.data[\"ids\"].append(data[\"ids\"][i])\n",
    "            end = min(len(premise), self.max_premise_length)\n",
    "            self.data[\"premises\"][i][:end] = torch.tensor(premise[:end])\n",
    "\n",
    "            hypothesis = data[\"hypotheses\"][i]\n",
    "            end = min(len(hypothesis), self.max_hypothesis_length)\n",
    "            self.data[\"hypotheses\"][i][:end] = torch.tensor(hypothesis[:end])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sequences\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\"id\": self.data[\"ids\"][index],\n",
    "                \"premise\": self.data[\"premises\"][index],\n",
    "                \"premise_length\": min(self.premises_lengths[index],\n",
    "                                      self.max_premise_length),\n",
    "                \"hypothesis\": self.data[\"hypotheses\"][index],\n",
    "                \"hypothesis_length\": min(self.hypotheses_lengths[index],\n",
    "                                         self.max_hypothesis_length),\n",
    "                \"label\": self.data[\"labels\"][index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ESIM model的工具函数\n",
    "\"\"\"\n",
    "\n",
    "def sort_by_seq_lens(batch, sequences_lengths, descending=True):\n",
    "    \"\"\"\n",
    "    根据句子序列长度排序\n",
    "    Args:\n",
    "        batch: 批，大小(batch_size ，max_sequence_length ，*)\n",
    "        sequences_lengths: A tensor containing the lengths of the sequences in the\n",
    "            input batch. The tensor should be of size (batch_size).\n",
    "        descending: A boolean value indicating whether to sort the sequences\n",
    "            by their lengths in descending order. Defaults to True.\n",
    "    Returns:\n",
    "        sorted_batch: A tensor containing the input batch reordered by\n",
    "            sequences lengths.\n",
    "        sorted_seq_lens: A tensor containing the sorted lengths of the\n",
    "            sequences in the input batch.\n",
    "        sorting_idx: A tensor containing the indices used to permute the input\n",
    "            batch in order to get 'sorted_batch'.\n",
    "        restoration_idx: A tensor containing the indices that can be used to\n",
    "            restore the order of the sequences in 'sorted_batch' so that it\n",
    "            matches the input batch.\n",
    "    \"\"\"\n",
    "    sorted_seq_lens, sorting_index =\\\n",
    "        sequences_lengths.sort(0, descending=descending)\n",
    "\n",
    "    sorted_batch = batch.index_select(0, sorting_index)\n",
    "\n",
    "    idx_range =\\\n",
    "        sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n",
    "    _, reverse_mapping = sorting_index.sort(0, descending=False)\n",
    "    restoration_index = idx_range.index_select(0, reverse_mapping)\n",
    "\n",
    "    return sorted_batch, sorted_seq_lens, sorting_index, restoration_index\n",
    "\n",
    "\n",
    "def get_mask(sequences_batch, sequences_lengths):\n",
    "    \"\"\"\n",
    "    Get the mask for a batch of padded variable length sequences.\n",
    "    Args:\n",
    "        sequences_batch: A batch of padded variable length sequences\n",
    "            containing word indices. Must be a 2-dimensional tensor of size\n",
    "            (batch, sequence).\n",
    "        sequences_lengths: A tensor containing the lengths of the sequences in\n",
    "            'sequences_batch'. Must be of size (batch).\n",
    "    Returns:\n",
    "        A mask of size (batch, max_sequence_length), where max_sequence_length\n",
    "        is the length of the longest sequence in the batch.\n",
    "    \"\"\"\n",
    "    batch_size = sequences_batch.size()[0]\n",
    "    max_length = torch.max(sequences_lengths)\n",
    "    mask = torch.ones(batch_size, max_length, dtype=torch.float)\n",
    "    mask[sequences_batch[:, :max_length] == 0] = 0.0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def masked_softmax(tensor, mask):\n",
    "    \"\"\"\n",
    "    Apply a masked softmax on the last dimension of a tensor.\n",
    "    The input tensor and mask should be of size (batch, *, sequence_length).\n",
    "    Args:\n",
    "        tensor: The tensor on which the softmax function must be applied along\n",
    "            the last dimension.\n",
    "        mask: A mask of the same size as the tensor with 0s in the positions of\n",
    "            the values that must be masked and 1s everywhere else.\n",
    "    Returns:\n",
    "        A tensor of the same size as the inputs containing the result of the\n",
    "        softmax.\n",
    "    \"\"\"\n",
    "    tensor_shape = tensor.size()\n",
    "    reshaped_tensor = tensor.view(-1, tensor_shape[-1])\n",
    "\n",
    "    # Reshape the mask so it matches the size of the input tensor.\n",
    "    while mask.dim() < tensor.dim():\n",
    "        mask = mask.unsqueeze(1)\n",
    "    mask = mask.expand_as(tensor).contiguous().float()\n",
    "    reshaped_mask = mask.view(-1, mask.size()[-1])\n",
    "\n",
    "    result = nn.functional.softmax(reshaped_tensor * reshaped_mask, dim=-1)\n",
    "    result = result * reshaped_mask\n",
    "    # 1e-13 is added to avoid divisions by zero.\n",
    "    result = result / (result.sum(dim=-1, keepdim=True) + 1e-13)\n",
    "\n",
    "    return result.view(*tensor_shape)\n",
    "\n",
    "def weighted_sum(tensor, weights, mask):\n",
    "    \"\"\"\n",
    "    Apply a weighted sum on the vectors along the last dimension of 'tensor',\n",
    "    and mask the vectors in the result with 'mask'.\n",
    "    Args:\n",
    "        tensor: A tensor of vectors on which a weighted sum must be applied.\n",
    "        weights: The weights to use in the weighted sum.\n",
    "        mask: A mask to apply on the result of the weighted sum.\n",
    "    Returns:\n",
    "        A new tensor containing the result of the weighted sum after the mask\n",
    "        has been applied on it.\n",
    "    \"\"\"\n",
    "    weighted_sum = weights.bmm(tensor)\n",
    "\n",
    "    while mask.dim() < weighted_sum.dim():\n",
    "        mask = mask.unsqueeze(1)\n",
    "    mask = mask.transpose(-1, -2)\n",
    "    mask = mask.expand_as(weighted_sum).contiguous().float()\n",
    "\n",
    "    return weighted_sum * mask\n",
    "\n",
    "def replace_masked(tensor, mask, value):\n",
    "    \"\"\"\n",
    "    Replace the all the values of vectors in 'tensor' that are masked in\n",
    "    'masked' by 'value'.\n",
    "    Args:\n",
    "        tensor: The tensor in which the masked vectors must have their values\n",
    "            replaced.\n",
    "        mask: A mask indicating the vectors which must have their values\n",
    "            replaced.\n",
    "        value: The value to place in the masked vectors of 'tensor'.\n",
    "    Returns:\n",
    "        A new tensor of the same size as 'tensor' where the values of the\n",
    "        vectors masked in 'mask' were replaced by 'value'.\n",
    "    \"\"\"\n",
    "    mask = mask.unsqueeze(1).transpose(2, 1)\n",
    "    reverse_mask = 1.0 - mask\n",
    "    values_to_add = value * reverse_mask\n",
    "    return tensor * mask + values_to_add\n",
    "\n",
    "\n",
    "def correct_predictions(output_probabilities, targets):\n",
    "    \"\"\"\n",
    "    Compute the number of predictions that match some target classes in the\n",
    "    output of a model.\n",
    "    Args:\n",
    "        output_probabilities: A tensor of probabilities for different output\n",
    "            classes.\n",
    "        targets: The indices of the actual target classes.\n",
    "    Returns:\n",
    "        The number of correct predictions in 'output_probabilities'.\n",
    "    \"\"\"\n",
    "    _, out_classes = output_probabilities.max(dim=1)\n",
    "    correct = (out_classes == targets).sum()\n",
    "    return correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of custom layers for the ESIM model.\n",
    "\"\"\"\n",
    "\n",
    "class RNNDropout(nn.Dropout):\n",
    "    \"\"\"\n",
    "    Dropout layer for the inputs of RNNs.\n",
    "    Apply the same dropout mask to all the elements of the same sequence in\n",
    "    a batch of sequences of size (batch, sequences_length, embedding_dim).\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, sequences_batch):\n",
    "        \"\"\"\n",
    "        Apply dropout to the input batch of sequences.\n",
    "        Args:\n",
    "            sequences_batch: A batch of sequences of vectors that will serve\n",
    "                as input to an RNN.\n",
    "                Tensor of size (batch, sequences_length, emebdding_dim).\n",
    "        Returns:\n",
    "            A new tensor on which dropout has been applied.\n",
    "        \"\"\"\n",
    "        ones = sequences_batch.data.new_ones(sequences_batch.shape[0],\n",
    "                                             sequences_batch.shape[-1])\n",
    "        dropout_mask = nn.functional.dropout(ones, self.p, self.training,\n",
    "                                             inplace=False)\n",
    "        return dropout_mask.unsqueeze(1) * sequences_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN taking variable length padded sequences of vectors as input and\n",
    "    encoding them into padded sequences of vectors of the same length.\n",
    "    This module is useful to handle batches of padded sequences of vectors\n",
    "    that have different lengths and that need to be passed through a RNN.\n",
    "    The sequences are sorted in descending order of their lengths, packed,\n",
    "    passed through the RNN, and the resulting sequences are then padded and\n",
    "    permuted back to the original order of the input sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 rnn_type,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 num_layers=1,\n",
    "                 bias=True,\n",
    "                 dropout=0.0,\n",
    "                 bidirectional=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rnn_type: The type of RNN to use as encoder in the module.\n",
    "                Must be a class inheriting from torch.nn.RNNBase\n",
    "                (such as torch.nn.LSTM for example).\n",
    "            input_size: The number of expected features in the input of the\n",
    "                module.\n",
    "            hidden_size: The number of features in the hidden state of the RNN\n",
    "                used as encoder by the module.\n",
    "            num_layers: The number of recurrent layers in the encoder of the\n",
    "                module. Defaults to 1.\n",
    "            bias: If False, the encoder does not use bias weights b_ih and\n",
    "                b_hh. Defaults to True.\n",
    "            dropout: If non-zero, introduces a dropout layer on the outputs\n",
    "                of each layer of the encoder except the last one, with dropout\n",
    "                probability equal to 'dropout'. Defaults to 0.0.\n",
    "            bidirectional: If True, the encoder of the module is bidirectional.\n",
    "                Defaults to False.\n",
    "        \"\"\"\n",
    "        assert issubclass(rnn_type, nn.RNNBase),\\\n",
    "            \"rnn_type must be a class inheriting from torch.nn.RNNBase\"\n",
    "\n",
    "        super(Seq2SeqEncoder, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self._encoder = rnn_type(input_size,\n",
    "                                 hidden_size,\n",
    "                                 num_layers=num_layers,\n",
    "                                 bias=bias,\n",
    "                                 batch_first=True,\n",
    "                                 dropout=dropout,\n",
    "                                 bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, sequences_batch, sequences_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequences_batch: A batch of variable length sequences of vectors.\n",
    "                The batch is assumed to be of size\n",
    "                (batch, sequence, vector_dim).\n",
    "            sequences_lengths: A 1D tensor containing the sizes of the\n",
    "                sequences in the input batch.\n",
    "        Returns:\n",
    "            reordered_outputs: The outputs (hidden states) of the encoder for\n",
    "                the sequences in the input batch, in the same order.\n",
    "        \"\"\"\n",
    "        sorted_batch, sorted_lengths, _, restoration_idx =\\\n",
    "            sort_by_seq_lens(sequences_batch, sequences_lengths)\n",
    "        packed_batch = nn.utils.rnn.pack_padded_sequence(sorted_batch,\n",
    "                                                         sorted_lengths,\n",
    "                                                         batch_first=True)\n",
    "\n",
    "        outputs, _ = self._encoder(packed_batch, None)\n",
    "\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs,\n",
    "                                                      batch_first=True)\n",
    "        reordered_outputs = outputs.index_select(0, restoration_idx)\n",
    "\n",
    "        return reordered_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention layer taking premises and hypotheses encoded by an RNN as input\n",
    "    and computing the soft attention between their elements.\n",
    "    The dot product of the encoded vectors in the premises and hypotheses is\n",
    "    first computed. The softmax of the result is then used in a weighted sum\n",
    "    of the vectors of the premises for each element of the hypotheses, and\n",
    "    conversely for the elements of the premises.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self,\n",
    "                premise_batch,\n",
    "                premise_mask,\n",
    "                hypothesis_batch,\n",
    "                hypothesis_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            premise_batch: A batch of sequences of vectors representing the\n",
    "                premises in some NLI task. The batch is assumed to have the\n",
    "                size (batch, sequences, vector_dim).\n",
    "            premise_mask: A mask for the sequences in the premise batch, to\n",
    "                ignore padding data in the sequences during the computation of\n",
    "                the attention.\n",
    "            hypothesis_batch: A batch of sequences of vectors representing the\n",
    "                hypotheses in some NLI task. The batch is assumed to have the\n",
    "                size (batch, sequences, vector_dim).\n",
    "            hypothesis_mask: A mask for the sequences in the hypotheses batch,\n",
    "                to ignore padding data in the sequences during the computation\n",
    "                of the attention.\n",
    "        Returns:\n",
    "            attended_premises: The sequences of attention vectors for the\n",
    "                premises in the input batch.\n",
    "            attended_hypotheses: The sequences of attention vectors for the\n",
    "                hypotheses in the input batch.\n",
    "        \"\"\"\n",
    "        # Dot product between premises and hypotheses in each sequence of\n",
    "        # the batch.\n",
    "        similarity_matrix = premise_batch.bmm(hypothesis_batch.transpose(2, 1)\n",
    "                                                              .contiguous())\n",
    "\n",
    "        # Softmax attention weights.\n",
    "        prem_hyp_attn = masked_softmax(similarity_matrix, hypothesis_mask)\n",
    "        hyp_prem_attn = masked_softmax(similarity_matrix.transpose(1, 2)\n",
    "                                                        .contiguous(),\n",
    "                                       premise_mask)\n",
    "\n",
    "        # Weighted sums of the hypotheses for the the premises attention,\n",
    "        # and vice-versa for the attention of the hypotheses.\n",
    "        attended_premises = weighted_sum(hypothesis_batch,\n",
    "                                         prem_hyp_attn,\n",
    "                                         premise_mask)\n",
    "        attended_hypotheses = weighted_sum(premise_batch,\n",
    "                                           hyp_prem_attn,\n",
    "                                           hypothesis_mask)\n",
    "\n",
    "        return attended_premises, attended_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_esim_weights(module):\n",
    "    \"\"\"\n",
    "    Initialization for ESIM\n",
    "    \"\"\"\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight.data)\n",
    "        nn.init.constant_(module.bias.data, 0.0)\n",
    "\n",
    "    elif isinstance(module, nn.LSTM):\n",
    "        nn.init.xavier_uniform_(module.weight_ih_l0.data)\n",
    "        nn.init.orthogonal_(module.weight_hh_l0.data)\n",
    "        nn.init.constant_(module.bias_ih_l0.data, 0.0)\n",
    "        nn.init.constant_(module.bias_hh_l0.data, 0.0)\n",
    "        hidden_size = module.bias_hh_l0.data.shape[0] // 4\n",
    "        module.bias_hh_l0.data[hidden_size:(2*hidden_size)] = 1.0\n",
    "\n",
    "        if (module.bidirectional):\n",
    "            nn.init.xavier_uniform_(module.weight_ih_l0_reverse.data)\n",
    "            nn.init.orthogonal_(module.weight_hh_l0_reverse.data)\n",
    "            nn.init.constant_(module.bias_ih_l0_reverse.data, 0.0)\n",
    "            nn.init.constant_(module.bias_hh_l0_reverse.data, 0.0)\n",
    "            module.bias_hh_l0_reverse.data[hidden_size:(2*hidden_size)] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESIM(nn.Module):\n",
    "    \"\"\"\n",
    "    ESIM model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, embeddings=None,\n",
    "                 padding_idx=0, dropout=0.5, num_classes=3, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: 词表大小\n",
    "            embedding_dim: 词向量维度\n",
    "            hidden_size: 隐藏层大小\n",
    "            embeddings: 词向量，大小为(vocab_size, embedding_dim)，默认None表示随机初始化\n",
    "            padding_idx: padding index，默认0\n",
    "            dropout: dropout rate，默认0.5\n",
    "            num_classes: 输出类别数，默认为3:E/N/C\n",
    "            device: model运行的设备，默认cpu\n",
    "        \"\"\"\n",
    "        super(ESIM, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        # =========================== Input Encoding ============================\n",
    "        # Embedding\n",
    "        self._word_embedding = nn.Embedding(self.vocab_size,\n",
    "                                            self.embedding_dim,\n",
    "                                            padding_idx=padding_idx,\n",
    "                                            _weight=embeddings)\n",
    "        # Dropout\n",
    "        if self.dropout:\n",
    "            self._rnn_dropout = RNNDropout(p=self.dropout)\n",
    "            # self._rnn_dropout = nn.Dropout(p=self.dropout)\n",
    "        \n",
    "        # biLSTM\n",
    "        self._encoding = Seq2SeqEncoder(nn.LSTM,\n",
    "                                        self.embedding_dim,\n",
    "                                        self.hidden_size,\n",
    "                                        bidirectional=True)\n",
    "        \n",
    "        # ========================== Local inference modeling =====================\n",
    "        # Attention\n",
    "        self._attention = SoftmaxAttention()\n",
    "\n",
    "        # Projection\n",
    "        self._projection = nn.Sequential(nn.Linear(4*2*self.hidden_size,\n",
    "                                                   self.hidden_size),\n",
    "                                         nn.ReLU())\n",
    "        \n",
    "        # ========================== inference composition ========================\n",
    "        # biLSTM\n",
    "        self._composition = Seq2SeqEncoder(nn.LSTM,\n",
    "                                           self.hidden_size,\n",
    "                                           self.hidden_size,\n",
    "                                           bidirectional=True)\n",
    "        # Prediction\n",
    "        self._classification = nn.Sequential(nn.Dropout(p=self.dropout),\n",
    "                                             nn.Linear(2*4*self.hidden_size,\n",
    "                                                       self.hidden_size),\n",
    "                                             nn.Tanh(),\n",
    "                                             nn.Dropout(p=self.dropout),\n",
    "                                             nn.Linear(self.hidden_size,\n",
    "                                                       self.num_classes))\n",
    "\n",
    "        # Initialization\n",
    "        self.apply(_init_esim_weights)\n",
    "\n",
    "    def forward(self, premises, premises_lengths, hypotheses, hypotheses_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            premises: (batch, premises_length).\n",
    "            premises_lengths: 'premises'中句子的长度.\n",
    "            hypothesis: A batch of varaible length sequences of word indices\n",
    "                representing hypotheses. The batch is assumed to be of size\n",
    "                (batch, hypotheses_length).\n",
    "            hypotheses_lengths: A 1D tensor containing the lengths of the\n",
    "                hypotheses in 'hypotheses'.\n",
    "        Returns:\n",
    "            logits: A tensor of size (batch, num_classes) containing the\n",
    "                logits for each output class of the model.\n",
    "            probabilities: A tensor of size (batch, num_classes) containing\n",
    "                the probabilities of each output class in the model.\n",
    "        \"\"\"\n",
    "        premises_mask = get_mask(premises, premises_lengths).to(self.device)\n",
    "        hypotheses_mask = get_mask(hypotheses, hypotheses_lengths)\\\n",
    "            .to(self.device)\n",
    "\n",
    "        embedded_premises = self._word_embedding(premises)\n",
    "        embedded_hypotheses = self._word_embedding(hypotheses)\n",
    "\n",
    "        if self.dropout:\n",
    "            embedded_premises = self._rnn_dropout(embedded_premises)\n",
    "            embedded_hypotheses = self._rnn_dropout(embedded_hypotheses)\n",
    "\n",
    "        encoded_premises = self._encoding(embedded_premises,\n",
    "                                          premises_lengths)\n",
    "        encoded_hypotheses = self._encoding(embedded_hypotheses,\n",
    "                                            hypotheses_lengths)\n",
    "\n",
    "        attended_premises, attended_hypotheses =\\\n",
    "            self._attention(encoded_premises, premises_mask,\n",
    "                            encoded_hypotheses, hypotheses_mask)\n",
    "\n",
    "        enhanced_premises = torch.cat([encoded_premises,\n",
    "                                       attended_premises,\n",
    "                                       encoded_premises - attended_premises,\n",
    "                                       encoded_premises * attended_premises],\n",
    "                                      dim=-1)\n",
    "        enhanced_hypotheses = torch.cat([encoded_hypotheses,\n",
    "                                         attended_hypotheses,\n",
    "                                         encoded_hypotheses -\n",
    "                                         attended_hypotheses,\n",
    "                                         encoded_hypotheses *\n",
    "                                         attended_hypotheses],\n",
    "                                        dim=-1)\n",
    "\n",
    "        projected_premises = self._projection(enhanced_premises)\n",
    "        projected_hypotheses = self._projection(enhanced_hypotheses)\n",
    "\n",
    "        if self.dropout:\n",
    "            projected_premises = self._rnn_dropout(projected_premises)\n",
    "            projected_hypotheses = self._rnn_dropout(projected_hypotheses)\n",
    "\n",
    "        v_ai = self._composition(projected_premises, premises_lengths)\n",
    "        v_bj = self._composition(projected_hypotheses, hypotheses_lengths)\n",
    "\n",
    "        v_a_avg = torch.sum(v_ai * premises_mask.unsqueeze(1)\n",
    "                                                .transpose(2, 1), dim=1)\\\n",
    "            / torch.sum(premises_mask, dim=1, keepdim=True)\n",
    "        v_b_avg = torch.sum(v_bj * hypotheses_mask.unsqueeze(1)\n",
    "                                                  .transpose(2, 1), dim=1)\\\n",
    "            / torch.sum(hypotheses_mask, dim=1, keepdim=True)\n",
    "\n",
    "        v_a_max, _ = replace_masked(v_ai, premises_mask, -1e7).max(dim=1)\n",
    "        v_b_max, _ = replace_masked(v_bj, hypotheses_mask, -1e7).max(dim=1)\n",
    "\n",
    "        v = torch.cat([v_a_avg, v_a_max, v_b_avg, v_b_max], dim=1)\n",
    "\n",
    "        logits = self._classification(v)\n",
    "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        return logits, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer,\n",
    "          criterion, epoch_number, max_gradient_norm):\n",
    "    \"\"\"\n",
    "    训练\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    device = model.device\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    batch_time_avg = 0.0\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "\n",
    "    tqdm_batch_iterator = tqdm(dataloader)\n",
    "    for batch_index, batch in enumerate(tqdm_batch_iterator):\n",
    "        batch_start = time.time()\n",
    "\n",
    "        premises = batch[\"premise\"].to(device)\n",
    "        premises_lengths = batch[\"premise_length\"].to(device)\n",
    "        hypotheses = batch[\"hypothesis\"].to(device)\n",
    "        hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, probs = model(premises,\n",
    "                              premises_lengths,\n",
    "                              hypotheses,\n",
    "                              hypotheses_lengths)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time_avg += time.time() - batch_start\n",
    "        running_loss += loss.item()\n",
    "        correct_preds += correct_predictions(probs, labels)\n",
    "\n",
    "        description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n",
    "                      .format(batch_time_avg/(batch_index+1),\n",
    "                              running_loss/(batch_index+1))\n",
    "        tqdm_batch_iterator.set_description(description)\n",
    "        \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = correct_preds / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_time, epoch_loss, epoch_accuracy\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion):\n",
    "    \"\"\"\n",
    "    验证\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            premises = batch[\"premise\"].to(device)\n",
    "            premises_lengths = batch[\"premise_length\"].to(device)\n",
    "            hypotheses = batch[\"hypothesis\"].to(device)\n",
    "            hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits, probs = model(premises,\n",
    "                                  premises_lengths,\n",
    "                                  hypotheses,\n",
    "                                  hypotheses_lengths)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += correct_predictions(probs, labels)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = running_accuracy / (len(dataloader.dataset))\n",
    "\n",
    "    return epoch_time, epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "在处理过的snli数据集上进行训练\n",
    "\"\"\"\n",
    "def main(train_file, valid_file, embeddings_file, target_dir, hidden_size=300,\n",
    "         dropout=0.5, num_classes=3, epochs=64, batch_size=32, lr=0.0004,\n",
    "         patience=5, max_grad_norm=10.0, checkpoint=None):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(30 * \"=\", \" Preparing for training \", 30 * \"=\")\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    # -------------------- 数据加载 ------------------- #\n",
    "    print(\"\\t* Loading training data...\")\n",
    "    with open(train_file, \"rb\") as pkl:\n",
    "        train_data = NLIDataset(pickle.load(pkl))\n",
    "\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    print(\"\\t* Loading validation data...\")\n",
    "    with open(valid_file, \"rb\") as pkl:\n",
    "        valid_data = NLIDataset(pickle.load(pkl))\n",
    "\n",
    "    valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    # -------------------- 模型构建 ------------------- #\n",
    "    print(\"\\t* Building model...\")\n",
    "    with open(embeddings_file, \"rb\") as pkl:\n",
    "        embeddings = torch.tensor(pickle.load(pkl), dtype=torch.float)\\\n",
    "                     .to(device)\n",
    "\n",
    "    model = ESIM(embeddings.shape[0],\n",
    "                 embeddings.shape[1],\n",
    "                 hidden_size,\n",
    "                 embeddings=embeddings,\n",
    "                 dropout=dropout,\n",
    "                 num_classes=num_classes,\n",
    "                 device=device).to(device)\n",
    "\n",
    "    # -------------------- 准备训练  ------------------- #\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                           mode=\"max\",\n",
    "                                                           factor=0.5,\n",
    "                                                           patience=0)\n",
    "\n",
    "    best_score = 0.0\n",
    "    start_epoch = 1\n",
    "\n",
    "    # 损失曲线数据list\n",
    "    epochs_count = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    # 从给定checkpoint继续训练\n",
    "    if checkpoint:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_score = checkpoint[\"best_score\"]\n",
    "\n",
    "        print(\"\\t* Training will continue on existing model from epoch {}...\"\n",
    "              .format(start_epoch))\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        epochs_count = checkpoint[\"epochs_count\"]\n",
    "        train_losses = checkpoint[\"train_losses\"]\n",
    "        valid_losses = checkpoint[\"valid_losses\"]\n",
    "\n",
    "    # 计算训练开始前的损失和精度\n",
    "    _, valid_loss, valid_accuracy = validate(model,\n",
    "                                             valid_loader,\n",
    "                                             criterion)\n",
    "    print(\"\\t* Validation loss before training: {:.4f}, accuracy: {:.4f}%\"\n",
    "          .format(valid_loss, (valid_accuracy*100)))\n",
    "\n",
    "    # -------------------- 迭代 ------------------- #\n",
    "    print(\"\\n\", 30 * \"=\",\"Training ESIM model on device: {}\".format(device),\n",
    "          30 * \"=\")\n",
    "\n",
    "    patience_counter = 0\n",
    "    for epoch in range(start_epoch, epochs+1):\n",
    "        epochs_count.append(epoch)\n",
    "\n",
    "        print(\"* Training epoch {}:\".format(epoch))\n",
    "        epoch_time, epoch_loss, epoch_accuracy = train(model,\n",
    "                                                       train_loader,\n",
    "                                                       optimizer,\n",
    "                                                       criterion,\n",
    "                                                       epoch,\n",
    "                                                       max_grad_norm)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(\"-> Training time: {:.4f}s, loss = {:.4f}, accuracy: {:.4f}%\"\n",
    "              .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
    "\n",
    "        print(\"* Validation for epoch {}:\".format(epoch))\n",
    "        epoch_time, epoch_loss, epoch_accuracy = validate(model,\n",
    "                                                          valid_loader,\n",
    "                                                          criterion)\n",
    "\n",
    "        valid_losses.append(epoch_loss)\n",
    "        print(\"-> Valid. time: {:.4f}s, loss: {:.4f}, accuracy: {:.4f}%\\n\"\n",
    "              .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step(epoch_accuracy)\n",
    "\n",
    "        # Early stopping on validation accuracy.\n",
    "        if epoch_accuracy < best_score:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            best_score = epoch_accuracy\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # 保存最优模型\n",
    "            torch.save({\"epoch\": epoch,\n",
    "                        \"model\": model.state_dict(),\n",
    "                        \"best_score\": best_score,\n",
    "                        \"epochs_count\": epochs_count,\n",
    "                        \"train_losses\": train_losses,\n",
    "                        \"valid_losses\": valid_losses},\n",
    "                       os.path.join(target_dir, \"best.pth.tar\"))\n",
    "\n",
    "        # 每轮保存模型\n",
    "        torch.save({\"epoch\": epoch,\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"best_score\": best_score,\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"epochs_count\": epochs_count,\n",
    "                    \"train_losses\": train_losses,\n",
    "                    \"valid_losses\": valid_losses},\n",
    "                   os.path.join(target_dir, \"esim_{}.pth.tar\".format(epoch)))\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
    "            break\n",
    "\n",
    "    # 损失曲线\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_count, train_losses, \"-r\")\n",
    "    plt.plot(epochs_count, valid_losses, \"-b\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "    plt.title(\"Cross entropy loss\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================  Preparing for training  ==============================\n",
      "\t* Loading training data...\n",
      "\t* Loading validation data...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "Avg. batch proc. time: 0.0584s, loss: 1.1730:   0%|          | 2/17168 [00:00<21:29, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 1.0987, accuracy: 34.6779%\n",
      "\n",
      " ============================== Training ESIM model on device: cuda:0 ==============================\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0631s, loss: 0.6483: 100%|██████████| 17168/17168 [18:52<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1132.8233s, loss = 0.6483, accuracy: 72.8036%\n",
      "* Validation for epoch 1:\n",
      "-> Valid. time: 9.3556s, loss: 0.4328, accuracy: 83.6822%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0939s, loss: 0.4907:   0%|          | 1/17168 [00:00<34:40,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0831s, loss: 0.4855: 100%|██████████| 17168/17168 [24:53<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1493.9665s, loss = 0.4855, accuracy: 81.0901%\n",
      "* Validation for epoch 2:\n",
      "-> Valid. time: 4.9777s, loss: 0.4090, accuracy: 84.6271%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0548s, loss: 0.4995:   0%|          | 2/17168 [00:00<19:42, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0587s, loss: 0.4384: 100%|██████████| 17168/17168 [17:33<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1053.9668s, loss = 0.4384, accuracy: 83.2689%\n",
      "* Validation for epoch 3:\n",
      "-> Valid. time: 5.0543s, loss: 0.3697, accuracy: 86.3138%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0545s, loss: 0.4665:   0%|          | 2/17168 [00:00<20:28, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0592s, loss: 0.4106: 100%|██████████| 17168/17168 [17:43<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1063.9419s, loss = 0.4106, accuracy: 84.5338%\n",
      "* Validation for epoch 4:\n",
      "-> Valid. time: 5.0329s, loss: 0.3597, accuracy: 86.6491%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0605s, loss: 0.4179:   0%|          | 2/17168 [00:00<21:29, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0593s, loss: 0.3906: 100%|██████████| 17168/17168 [17:44<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1064.9428s, loss = 0.3906, accuracy: 85.3267%\n",
      "* Validation for epoch 5:\n",
      "-> Valid. time: 4.9961s, loss: 0.3474, accuracy: 87.2384%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0542s, loss: 0.4670:   0%|          | 2/17168 [00:00<19:59, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0591s, loss: 0.3764: 100%|██████████| 17168/17168 [17:42<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1062.0679s, loss = 0.3764, accuracy: 86.0461%\n",
      "* Validation for epoch 6:\n",
      "-> Valid. time: 4.9768s, loss: 0.3491, accuracy: 87.4619%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0557s, loss: 0.3009:   0%|          | 2/17168 [00:00<20:03, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0589s, loss: 0.3644: 100%|██████████| 17168/17168 [17:35<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1055.8994s, loss = 0.3644, accuracy: 86.5487%\n",
      "* Validation for epoch 7:\n",
      "-> Valid. time: 4.9189s, loss: 0.3426, accuracy: 87.5635%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0540s, loss: 0.2842:   0%|          | 2/17168 [00:00<19:19, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0585s, loss: 0.3551: 100%|██████████| 17168/17168 [17:31<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1051.4614s, loss = 0.3551, accuracy: 86.9513%\n",
      "* Validation for epoch 8:\n",
      "-> Valid. time: 4.9924s, loss: 0.3394, accuracy: 87.6753%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0573s, loss: 0.3746:   0%|          | 2/17168 [00:00<20:32, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0677s, loss: 0.3458: 100%|██████████| 17168/17168 [20:14<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1214.4164s, loss = 0.3458, accuracy: 87.2506%\n",
      "* Validation for epoch 9:\n",
      "-> Valid. time: 7.7495s, loss: 0.3430, accuracy: 88.0817%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0795s, loss: 0.2143:   0%|          | 1/17168 [00:00<31:46,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0642s, loss: 0.3391: 100%|██████████| 17168/17168 [19:12<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1152.4019s, loss = 0.3391, accuracy: 87.6239%\n",
      "* Validation for epoch 10:\n",
      "-> Valid. time: 4.9849s, loss: 0.3450, accuracy: 87.7870%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_config = \"config/snli_training.json\" # 训练的配置文件\n",
    "with open(default_config, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "    main(os.path.normpath(config[\"train_data\"]),\n",
    "         os.path.normpath(config[\"valid_data\"]),\n",
    "         os.path.normpath(config[\"embeddings\"]),\n",
    "         os.path.normpath(config[\"target_dir\"]),\n",
    "         config[\"hidden_size\"],\n",
    "         config[\"dropout\"],\n",
    "         config[\"num_classes\"],\n",
    "         config[\"epochs\"],\n",
    "         config[\"batch_size\"],\n",
    "         config[\"lr\"],\n",
    "         config[\"patience\"],\n",
    "         config[\"max_gradient_norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    \"\"\"\n",
    "    测试\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    time_start = time.time()\n",
    "    batch_time = 0.0\n",
    "    accuracy = 0.0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch_start = time.time()\n",
    "\n",
    "            premises = batch[\"premise\"].to(device)\n",
    "            premises_lengths = batch[\"premise_length\"].to(device)\n",
    "            hypotheses = batch[\"hypothesis\"].to(device)\n",
    "            hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            _, probs = model(premises,\n",
    "                             premises_lengths,\n",
    "                             hypotheses,\n",
    "                             hypotheses_lengths)\n",
    "\n",
    "            accuracy += correct_predictions(probs, labels)\n",
    "            batch_time += time.time() - batch_start\n",
    "\n",
    "    batch_time /= len(dataloader)\n",
    "    total_time = time.time() - time_start\n",
    "    accuracy /= (len(dataloader.dataset))\n",
    "\n",
    "    return batch_time, total_time, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在snli test数据集上进行测试\n",
    "def main2(test_file, pretrained_file, batch_size=32):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(30 * \"=\", \" Preparing for testing \", 30 * \"=\")\n",
    "\n",
    "    checkpoint = torch.load(pretrained_file)\n",
    "\n",
    "    vocab_size = checkpoint[\"model\"][\"_word_embedding.weight\"].size(0)\n",
    "    embedding_dim = checkpoint[\"model\"]['_word_embedding.weight'].size(1)\n",
    "    hidden_size = checkpoint[\"model\"][\"_projection.0.weight\"].size(0)\n",
    "    num_classes = checkpoint[\"model\"][\"_classification.4.weight\"].size(0)\n",
    "\n",
    "    print(\"\\t* Loading test data...\")\n",
    "    with open(test_file, \"rb\") as pkl:\n",
    "        test_data = NLIDataset(pickle.load(pkl))\n",
    "\n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    print(\"\\t* Building model...\")\n",
    "    model = ESIM(vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_size,\n",
    "                 num_classes=num_classes,\n",
    "                 device=device).to(device)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "    print(30 * \"=\", \" Testing ESIM model on device: {} \".format(device),\n",
    "          30 * \"=\")\n",
    "    batch_time, total_time, accuracy = test(model, test_loader)\n",
    "\n",
    "    print(\"-> Average batch processing time: {:.4f}s, total test time:\\\n",
    " {:.4f}s, accuracy: {:.4f}%\".format(batch_time, total_time, (accuracy*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================  Preparing for testing  ==============================\n",
      "\t* Loading test data...\n",
      "\t* Building model...\n",
      "==============================  Testing ESIM model on device: cuda:0  ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Average batch processing time: 0.0106s, total test time: 3.3802s, accuracy: 86.8587%\n"
     ]
    }
   ],
   "source": [
    "# load最优模型进行测试\n",
    "main2(\"data_task3/preprocessed/SNLI/test_data.pkl\",\n",
    "    \"data_task3/checkpoints/SNLI/best.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
